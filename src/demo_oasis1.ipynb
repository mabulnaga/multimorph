{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c89d4f5f",
      "metadata": {
        "id": "c89d4f5f"
      },
      "source": [
        "# MultiMorph Demo on OASIS-1 (2D)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mabulnaga/multimorph.git\n",
        "%cd multimorph/src"
      ],
      "metadata": {
        "id": "MeQD9R9oapE_"
      },
      "id": "MeQD9R9oapE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "03550f45",
      "metadata": {
        "id": "03550f45"
      },
      "source": [
        "### Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install neurite\n",
        "!pip install monai --no-deps\n",
        "!pip install git+https://github.com/adalca/neurite.git --force-reinstall --no-deps\n",
        "!pip install pystrum\n",
        "#!pip install voxelmorph"
      ],
      "metadata": {
        "id": "8S_LPWeY-oBz"
      },
      "id": "8S_LPWeY-oBz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f408d207",
      "metadata": {
        "id": "f408d207"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "os.environ['NEURITE_BACKEND'] = 'pytorch'\n",
        "os.environ['VXM_BACKEND'] = 'pytorch'\n",
        "import neurite as ne\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d409c5",
      "metadata": {
        "id": "26d409c5"
      },
      "source": [
        "# OASIS-1 Data\n",
        "download OASIS-1 2D Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da9a083",
      "metadata": {
        "id": "8da9a083"
      },
      "outputs": [],
      "source": [
        "!mkdir -p oasisdata\n",
        "!wget -q https://surfer.nmr.mgh.harvard.edu/ftp/data/neurite/data/neurite-oasis.2d.v1.0.tar\n",
        "!tar xf neurite-oasis.2d.v1.0.tar -C oasisdata/\n",
        "!rm neurite-oasis.2d.v1.0.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2fc5d5a",
      "metadata": {
        "id": "d2fc5d5a"
      },
      "source": [
        "### Load the OASIS Data\n",
        "stack the data together to a tensor to create a dataloader from. Specify the path where the oasis data lives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d4f4741",
      "metadata": {
        "id": "5d4f4741"
      },
      "outputs": [],
      "source": [
        "# specify the full path to the OASIS data\n",
        "oasis_data_path ='oasisdata'\n",
        "\n",
        "files = [f/'slice_norm.nii.gz' for f in pathlib.Path(oasis_data_path).iterdir() if f.is_dir()]\n",
        "slices = [torch.from_numpy(nib.load(f).get_fdata())[..., 0] for f in files]\n",
        "oasis_data = torch.stack(slices, dim=0).float().to(device) # put all data on cuda.\n",
        "\n",
        "# get the segmentations\n",
        "seg_files = [f/'slice_seg4.nii.gz' for f in pathlib.Path(oasis_data_path).iterdir() if f.is_dir()]\n",
        "seg_slices = [torch.from_numpy(nib.load(f).get_fdata())[...,0] for f in seg_files]\n",
        "oasis_data_segmentation = torch.stack(seg_slices,dim=0).float().to(device)\n",
        "\n",
        "\n",
        "oasis_data = oasis_data.transpose(2, 1)\n",
        "oasis_data_segmentation = oasis_data_segmentation.transpose(2,1).unsqueeze(1)\n",
        "\n",
        "print(oasis_data.shape)\n",
        "print(oasis_data_segmentation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235d56bf",
      "metadata": {
        "id": "235d56bf"
      },
      "source": [
        "### Create a 80/20 split between train and test.\n",
        "The train data loader will randomly sample between 2 and 12 images per iteration. The test data loader will construct an atlas on the entire test set.\n",
        "\n",
        "The `GroupDataLoader` samples random subsamples of the dataset. The `SubGroupLoader` samples the entire dataset. We use the `SubGroupLoader` to construct an atlas for the test set.\n",
        "This data loader assumes the tensors are wrapped in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f14413",
      "metadata": {
        "id": "c7f14413"
      },
      "outputs": [],
      "source": [
        "from dataloader import GroupDataLoader, SubGroupLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# number of images to sample at each training iteration\n",
        "n_inputs_range = [2,12]\n",
        "\n",
        "#split into train and test (80/20)\n",
        "train_pct = 0.8\n",
        "N_data = len(oasis_data)\n",
        "N_train = int(N_data * train_pct)\n",
        "N_test = N_data - N_train\n",
        "range_data = np.arange(0,N_data)\n",
        "train_idx = np.random.choice(range_data, N_train, replace=False)\n",
        "test_idx =np.setdiff1d(range_data, train_idx)\n",
        "\n",
        "# split the image and segmentations into the appropriate data split\n",
        "oasis_data_train = oasis_data[train_idx,:]\n",
        "oasis_data_test = oasis_data[test_idx,:]\n",
        "oasis_data_segmentation_train = oasis_data_segmentation[train_idx,:]\n",
        "oasis_data_segmentation_test = oasis_data_segmentation[test_idx,:]\n",
        "\n",
        "# create data loaders for train and test. The GroupDataLoader will randomly sample n_input_ranges image at each iteration.\n",
        "# for the test data loader, we load the entire test set.\n",
        "\n",
        "dataset_oasis_train = GroupDataLoader(data=oasis_data_train,labels=np.zeros(N_train), class_labels=[0],\n",
        "                                      segmentations=oasis_data_segmentation_train, n_inputs_range=n_inputs_range,transform=None)\n",
        "dataloader_oasis_train = DataLoader(dataset_oasis_train,batch_size=1,shuffle=True)\n",
        "\n",
        "dataset_oasis_test = SubGroupLoader(data=[oasis_data_test],labels=None, # labels=[np.zeros(N_test)],\n",
        "                                     segmentations=[oasis_data_segmentation_test], transform=None)\n",
        "dataloader_oasis_test = DataLoader(dataset_oasis_test, batch_size=1, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e9e364",
      "metadata": {
        "id": "f0e9e364"
      },
      "source": [
        "#### Visualize a few samples from the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc93576",
      "metadata": {
        "id": "8cc93576"
      },
      "outputs": [],
      "source": [
        "# grab two sets of samples from the training dataloader and visualize.\n",
        "for i in range(0,2):\n",
        "    sample = next(iter(dataloader_oasis_train))\n",
        "    images = sample['image']\n",
        "    segmentations = sample['segmentation']\n",
        "    # undo one-hot encoding\n",
        "    segmentations = torch.argmax(segmentations, dim=2, keepdim=True)\n",
        "    # plot images\n",
        "    slices = [f for f in images[0, :, 0, ...].cpu().detach().numpy()]\n",
        "    ne.py.plot.slices(slices,do_colorbars=True)\n",
        "    # plot segmentations\n",
        "    slices_seg = [f for f in segmentations[0, :, 0, ...].cpu().detach().numpy()]\n",
        "    ne.py.plot.slices(slices_seg,do_colorbars=True, cmaps=['turbo']*len(slices_seg))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9abddccc",
      "metadata": {
        "id": "9abddccc"
      },
      "source": [
        "# Setup the Model and Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66924564",
      "metadata": {
        "id": "66924564"
      },
      "outputs": [],
      "source": [
        "import models as models\n",
        "import layers as layers\n",
        "import losses as losses\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7524734",
      "metadata": {
        "id": "f7524734"
      },
      "source": [
        "#### get the image size to set up the Spatial Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166a3a1d",
      "metadata": {
        "id": "166a3a1d"
      },
      "outputs": [],
      "source": [
        "oasis_img_size = list(map(int, list(oasis_data.shape[1:])))\n",
        "print(oasis_img_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2fef9ba",
      "metadata": {
        "id": "c2fef9ba"
      },
      "source": [
        "### setup the loss functions\n",
        "We will use a combination of local NCC loss on image similarity, l2 regularization on the determinant of the deformation field, and Dice loss on the brain structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3535d7c8",
      "metadata": {
        "id": "3535d7c8"
      },
      "outputs": [],
      "source": [
        "img_size = torch.Size(oasis_img_size)\n",
        "\n",
        "# image and regularization loss\n",
        "criterion = losses.local_NCC_2d(volshape=img_size, lbd=1) #0.01\n",
        "#criterion = losses.MinVarAndGrad2d(volshape=img_size, lbd=0.1) #0.01\n",
        "\n",
        "# segmentation loss\n",
        "seg_loss = losses.DiceWarpLoss2d(img_size)\n",
        "lambda_seg = 0.5\n",
        "\n",
        "mmnet = models.GroupNet(in_channels=1, out_channels=2, img_size=img_size).to(device)  # updated note: have vxms.models.MultiMorph now.\n",
        "\n",
        "optimizer = optim.Adam(mmnet.parameters(), lr=0.001) #0.01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce2cd61",
      "metadata": {
        "id": "7ce2cd61"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf766288",
      "metadata": {
        "id": "bf766288"
      },
      "outputs": [],
      "source": [
        "nb_epochs = 100\n",
        "batch_size = 1\n",
        "data_loader = dataloader_oasis_train\n",
        "# move the model to the device\n",
        "mmnet = mmnet.to(device)\n",
        "\n",
        "pbar = trange(nb_epochs)\n",
        "loss_hist = np.zeros(nb_epochs)\n",
        "\n",
        "for i in pbar:\n",
        "    total_running_loss = list()\n",
        "    mmnet.train()\n",
        "    for sample in data_loader:\n",
        "        images = sample['image'].to(device)\n",
        "        segmentations = sample['segmentation'].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # predict the warp fields\n",
        "        predw = mmnet(images)\n",
        "        # compute the loss\n",
        "        loss = criterion(images, predw)\n",
        "        loss_seg = seg_loss(segmentations,predw)\n",
        "        loss = loss + lambda_seg * loss_seg\n",
        "        total_running_loss.append(loss.item())\n",
        "        #optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # print stats\n",
        "    m = np.mean(total_running_loss)\n",
        "    pbar.set_description(f'{m:.5f}')\n",
        "    loss_hist[i] = m\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0279d288",
      "metadata": {
        "id": "0279d288"
      },
      "source": [
        "#### Visualize the training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14084105",
      "metadata": {
        "id": "14084105"
      },
      "outputs": [],
      "source": [
        "# lets quickly see the training curve\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(loss_hist)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.title('Training Loss')\n",
        "plt.grid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c97c19",
      "metadata": {
        "id": "10c97c19"
      },
      "source": [
        "# Visualize the warps and atlas on sampels from the train set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72966668",
      "metadata": {
        "id": "72966668"
      },
      "source": [
        "### setup a few plotting and warping functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21ddda9",
      "metadata": {
        "id": "f21ddda9"
      },
      "outputs": [],
      "source": [
        "from utils import warp_seg, warp_image, warp_grid, setup_grid_tensor, plot_row_slices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a907b40d",
      "metadata": {
        "id": "a907b40d"
      },
      "source": [
        "### load a sample and plot the images and segmentations after warping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4f9954",
      "metadata": {
        "id": "cc4f9954"
      },
      "outputs": [],
      "source": [
        "img_size = oasis_img_size\n",
        "dataset = dataset_oasis_train\n",
        "warp_dim = img_size\n",
        "\n",
        "# set up the train data loader\n",
        "mmnet.to(device)\n",
        "gen =  iter(DataLoader(dataset,batch_size=1,shuffle=False))\n",
        "\n",
        "# grab a sample from the data loader\n",
        "sample = next(gen)\n",
        "images = sample['image'].to(device)\n",
        "segs = sample['segmentation'].to(device)\n",
        "N_images = np.shape(images)[1]\n",
        "\n",
        "# warp and plot original, warped images\n",
        "warped, predicted_warp = warp_image(images,mmnet,img_size)\n",
        "warped_seg = warp_seg(segs, predicted_warp, img_size=img_size)\n",
        "\n",
        "# plot the original and warped images\n",
        "plot_row_slices(images, do_colorbars=False, suptitle='Original Images')\n",
        "plot_row_slices(warped, do_colorbars=False, suptitle='Warped Images')\n",
        "\n",
        "# plot the original and warped segmentations\n",
        "plot_row_slices(torch.round(torch.argmax(segs, dim=2, keepdim=True)), do_colorbars=False, cmaps=['turbo']*N_images, suptitle='Original Segmentations')\n",
        "plot_row_slices(torch.round(torch.argmax(warped_seg, dim=2, keepdim=True)), do_colorbars=False, cmaps=['turbo']*N_images, suptitle='Warped Segmentations')\n",
        "\n",
        "# Create a grid and plot the warped grid\n",
        "grids = setup_grid_tensor(N_slices=N_images,spacing=5, img_size=img_size).to(device)\n",
        "warped_grid = warp_grid(grids, predicted_warp, warp_dim=img_size)\n",
        "plot_row_slices(warped_grid, do_colorbars=False, suptitle='Warped Grid')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5afb6cfe",
      "metadata": {
        "id": "5afb6cfe"
      },
      "source": [
        "### visualize the resultant atlases, and compare to constructing an atlas by taking the mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cffdefa",
      "metadata": {
        "id": "0cffdefa"
      },
      "outputs": [],
      "source": [
        "# plot mean shapes\n",
        "atl = torch.mean(images, dim=1, keepdims=True)\n",
        "atlw = torch.mean(warped, dim=1, keepdims=True)\n",
        "slices = [f.cpu().detach().numpy() for f in [atl, atlw]]\n",
        "titles = ['Atlas Computed by Taking the Mean', 'MultiMorph Atlas']\n",
        "ne.plot.slices(slices, do_colorbars=True, titles=titles)\n",
        "\n",
        "# plot mean segmentations\n",
        "mean_seg = torch.round(torch.argmax(torch.mean(segs,dim=1,keepdim=True), dim=2, keepdims=True))\n",
        "mean_warped_seg = torch.round(torch.argmax(torch.mean(warped_seg, dim=1, keepdims=True), dim=2, keepdim=True))\n",
        "slices = [f.cpu().detach().numpy() for f in [mean_seg, mean_warped_seg]]\n",
        "titles = ['Segmentations of Mean Atlas', 'Segmentations of MultiMorph Atlas']\n",
        "ne.plot.slices(slices, do_colorbars=True, titles=titles, cmaps=['turbo']*len(slices))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33187e67",
      "metadata": {
        "id": "33187e67"
      },
      "source": [
        "# Construct an Atlas on the Entire Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5153d75c",
      "metadata": {
        "id": "5153d75c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "mmnet = mmnet.to('cpu')\n",
        "mmnet.eval()\n",
        "warp_layer = layers.group.Warp2d(img_size)\n",
        "for sample in dataloader_oasis_test:\n",
        "    st = time.time()\n",
        "    images = sample['image'].to('cpu')\n",
        "    segmentations = sample['segmentation'].to('cpu')\n",
        "    # predict the warp fields\n",
        "    predw = mmnet(images)\n",
        "\n",
        "    # warp and plot original, warped images\n",
        "    warped = warp_layer(images, predw)\n",
        "    warped_seg = warp_layer(segmentations, predw)\n",
        "    #warped_seg = warp_seg(segmentations, predicted_warp, img_size=img_size)\n",
        "\n",
        "# construct the atlases\n",
        "atlas = torch.mean(warped, dim=1, keepdims=True)\n",
        "atlas_segmentation = torch.round(torch.argmax(torch.mean(warped_seg, dim=1, keepdims=True), dim=2, keepdim=True))\n",
        "\n",
        "et = time.time()\n",
        "print(f'Atlas Construction took {et-st:.3f} seconds for {images.shape[1]} images')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d4dc429",
      "metadata": {
        "id": "8d4dc429"
      },
      "source": [
        "#### plot the constructed atlases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecc9e26",
      "metadata": {
        "id": "fecc9e26"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot these two side by side\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(atlas[0, 0, 0, ...].cpu().detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('MultiMorph Atlas')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(atlas_segmentation[0, 0, 0, ...].cpu().detach().numpy(), cmap='turbo')\n",
        "plt.axis('off')\n",
        "plt.title('Segmentations of MultiMorph Atlas')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50378049",
      "metadata": {
        "id": "50378049"
      },
      "source": [
        "### save the atlases (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf28d39",
      "metadata": {
        "id": "5cf28d39"
      },
      "outputs": [],
      "source": [
        "atlas_path = 'oasis_atlas_2d.nii.gz'\n",
        "atlas_segmentation_path = 'oasis_atlas_segmentation_2d.nii.gz'\n",
        "nib.save(nib.Nifti1Image(atlas[0, 0, 0, ...].cpu().detach().numpy(), np.eye(4)), atlas_path)\n",
        "nib.save(nib.Nifti1Image(atlas_segmentation[0, 0, 0, ...].float().cpu().detach().numpy(), np.eye(4)), atlas_segmentation_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mapping",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}