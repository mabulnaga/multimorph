{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c89d4f5f",
      "metadata": {
        "id": "c89d4f5f"
      },
      "source": [
        "# MultiMorph Demo on OASIS-1 (2D)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03550f45",
      "metadata": {
        "id": "03550f45"
      },
      "source": [
        "### Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neurite\n",
        "!pip install voxelmorph"
      ],
      "metadata": {
        "id": "8S_LPWeY-oBz",
        "outputId": "c8621183-c284-4e63-cc47-0abaf40c0bef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8S_LPWeY-oBz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neurite\n",
            "  Downloading neurite-0.2-py3-none-any.whl.metadata (653 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from neurite) (24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from neurite) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from neurite) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from neurite) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from neurite) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from neurite) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from neurite) (1.6.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from neurite) (5.3.2)\n",
            "Collecting pystrum>=0.2 (from neurite)\n",
            "  Downloading pystrum-0.4.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->neurite) (6.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->neurite) (4.14.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->neurite) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->neurite) (3.6.0)\n",
            "Downloading neurite-0.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pystrum\n",
            "  Building wheel for pystrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystrum: filename=pystrum-0.4-py3-none-any.whl size=19533 sha256=19e24538aae8b410df41aa5a5609053f4417370ddd75f05b05952f0fbb1e5666\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/55/bd/7ac4dce19665c612e18993f517312c7ebabeaafed479bc4aac\n",
            "Successfully built pystrum\n",
            "Installing collected packages: pystrum, neurite\n",
            "Successfully installed neurite-0.2 pystrum-0.4\n",
            "Collecting voxelmorph\n",
            "  Downloading voxelmorph-0.2-py3-none-any.whl.metadata (660 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (24.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (0.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (3.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (1.15.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (5.3.2)\n",
            "Requirement already satisfied: neurite>=0.2 in /usr/local/lib/python3.11/dist-packages (from voxelmorph) (0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from neurite>=0.2->voxelmorph) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from neurite>=0.2->voxelmorph) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from neurite>=0.2->voxelmorph) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from neurite>=0.2->voxelmorph) (1.6.1)\n",
            "Requirement already satisfied: pystrum>=0.2 in /usr/local/lib/python3.11/dist-packages (from neurite>=0.2->voxelmorph) (0.4)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->voxelmorph) (6.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->voxelmorph) (4.14.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->voxelmorph) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->voxelmorph) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->voxelmorph) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->voxelmorph) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->voxelmorph) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite>=0.2->voxelmorph) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite>=0.2->voxelmorph) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite>=0.2->voxelmorph) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite>=0.2->voxelmorph) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite>=0.2->voxelmorph) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurite>=0.2->voxelmorph) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->neurite>=0.2->voxelmorph) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->neurite>=0.2->voxelmorph) (3.6.0)\n",
            "Downloading voxelmorph-0.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: voxelmorph\n",
            "Successfully installed voxelmorph-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f408d207",
      "metadata": {
        "id": "f408d207",
        "outputId": "bd81f328-35a3-455a-db63-eff531bbc8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'neurite'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-398772361>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NEURITE_BACKEND'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VXM_BACKEND'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneurite\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neurite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# imports\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "os.environ['NEURITE_BACKEND'] = 'pytorch'\n",
        "os.environ['VXM_BACKEND'] = 'pytorch'\n",
        "import neurite as ne\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d409c5",
      "metadata": {
        "id": "26d409c5"
      },
      "source": [
        "# OASIS-1 Data\n",
        "download OASIS-1 2D Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da9a083",
      "metadata": {
        "id": "8da9a083"
      },
      "outputs": [],
      "source": [
        "!mkdir -p oasisdata\n",
        "!wget -q https://surfer.nmr.mgh.harvard.edu/ftp/data/neurite/data/neurite-oasis.2d.v1.0.tar\n",
        "!tar xf neurite-oasis.2d.v1.0.tar -C oasisdata/\n",
        "!rm neurite-oasis.2d.v1.0.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2fc5d5a",
      "metadata": {
        "id": "d2fc5d5a"
      },
      "source": [
        "### Load the OASIS Data\n",
        "stack the data together to a tensor to create a dataloader from. Specify the path where the oasis data lives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d4f4741",
      "metadata": {
        "id": "5d4f4741"
      },
      "outputs": [],
      "source": [
        "# specify the full path to the OASIS data\n",
        "oasis_data_path ='oasisdata'\n",
        "\n",
        "files = [f/'slice_norm.nii.gz' for f in pathlib.Path(oasis_data_path).iterdir() if f.is_dir()]\n",
        "slices = [torch.from_numpy(nib.load(f).get_fdata())[..., 0] for f in files]\n",
        "oasis_data = torch.stack(slices, dim=0).float().to(device) # put all data on cuda.\n",
        "\n",
        "# get the segmentations\n",
        "seg_files = [f/'slice_seg4.nii.gz' for f in pathlib.Path(oasis_data_path).iterdir() if f.is_dir()]\n",
        "seg_slices = [torch.from_numpy(nib.load(f).get_fdata())[...,0] for f in seg_files]\n",
        "oasis_data_segmentation = torch.stack(seg_slices,dim=0).float().to(device)\n",
        "\n",
        "\n",
        "oasis_data = oasis_data.transpose(2, 1)\n",
        "oasis_data_segmentation = oasis_data_segmentation.transpose(2,1).unsqueeze(1)\n",
        "\n",
        "print(oasis_data.shape)\n",
        "print(oasis_data_segmentation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235d56bf",
      "metadata": {
        "id": "235d56bf"
      },
      "source": [
        "### Create a 80/20 split between train and test.\n",
        "The train data loader will randomly sample between 2 and 12 images per iteration. The test data loader will construct an atlas on the entire test set.\n",
        "\n",
        "The `GroupDataLoader` samples random subsamples of the dataset. The `SubGroupLoader` samples the entire dataset. We use the `SubGroupLoader` to construct an atlas for the test set.\n",
        "This data loader assumes the tensors are wrapped in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f14413",
      "metadata": {
        "id": "c7f14413"
      },
      "outputs": [],
      "source": [
        "from dataloader import GroupDataLoader, SubGroupLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# number of images to sample at each training iteration\n",
        "n_inputs_range = [2,12]\n",
        "\n",
        "#split into train and test (80/20)\n",
        "train_pct = 0.8\n",
        "N_data = len(oasis_data)\n",
        "N_train = int(N_data * train_pct)\n",
        "N_test = N_data - N_train\n",
        "range_data = np.arange(0,N_data)\n",
        "train_idx = np.random.choice(range_data, N_train, replace=False)\n",
        "test_idx =np.setdiff1d(range_data, train_idx)\n",
        "\n",
        "# split the image and segmentations into the appropriate data split\n",
        "oasis_data_train = oasis_data[train_idx,:]\n",
        "oasis_data_test = oasis_data[test_idx,:]\n",
        "oasis_data_segmentation_train = oasis_data_segmentation[train_idx,:]\n",
        "oasis_data_segmentation_test = oasis_data_segmentation[test_idx,:]\n",
        "\n",
        "# create data loaders for train and test. The GroupDataLoader will randomly sample n_input_ranges image at each iteration.\n",
        "# for the test data loader, we load the entire test set.\n",
        "\n",
        "dataset_oasis_train = GroupDataLoader(data=oasis_data_train,labels=np.zeros(N_train), class_labels=[0],\n",
        "                                      segmentations=oasis_data_segmentation_train, n_inputs_range=n_inputs_range,transform=None)\n",
        "dataloader_oasis_train = DataLoader(dataset_oasis_train,batch_size=1,shuffle=True)\n",
        "\n",
        "dataset_oasis_test = SubGroupLoader(data=[oasis_data_test],labels=None, # labels=[np.zeros(N_test)],\n",
        "                                     segmentations=[oasis_data_segmentation_test], transform=None)\n",
        "dataloader_oasis_test = DataLoader(dataset_oasis_test, batch_size=1, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e9e364",
      "metadata": {
        "id": "f0e9e364"
      },
      "source": [
        "#### Visualize a few samples from the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc93576",
      "metadata": {
        "id": "8cc93576"
      },
      "outputs": [],
      "source": [
        "# grab two sets of samples from the training dataloader and visualize.\n",
        "for i in range(0,2):\n",
        "    sample = next(iter(dataloader_oasis_train))\n",
        "    images = sample['image']\n",
        "    segmentations = sample['segmentation']\n",
        "    # undo one-hot encoding\n",
        "    segmentations = torch.argmax(segmentations, dim=2, keepdim=True)\n",
        "    # plot images\n",
        "    slices = [f for f in images[0, :, 0, ...].cpu().detach().numpy()]\n",
        "    ne.plot.slices(slices,do_colorbars=True)\n",
        "    # plot segmentations\n",
        "    slices_seg = [f for f in segmentations[0, :, 0, ...].cpu().detach().numpy()]\n",
        "    ne.plot.slices(slices_seg,do_colorbars=True, cmaps=['turbo']*len(slices_seg))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9abddccc",
      "metadata": {
        "id": "9abddccc"
      },
      "source": [
        "# Setup the Model and Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66924564",
      "metadata": {
        "id": "66924564"
      },
      "outputs": [],
      "source": [
        "import models as models\n",
        "import layers as layers\n",
        "import losses as losses\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7524734",
      "metadata": {
        "id": "f7524734"
      },
      "source": [
        "#### get the image size to set up the Spatial Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166a3a1d",
      "metadata": {
        "id": "166a3a1d"
      },
      "outputs": [],
      "source": [
        "oasis_img_size = list(map(int, list(oasis_data.shape[1:])))\n",
        "print(oasis_img_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2fef9ba",
      "metadata": {
        "id": "c2fef9ba"
      },
      "source": [
        "### setup the loss functions\n",
        "We will use a combination of local NCC loss on image similarity, l2 regularization on the determinant of the deformation field, and Dice loss on the brain structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3535d7c8",
      "metadata": {
        "id": "3535d7c8"
      },
      "outputs": [],
      "source": [
        "img_size = torch.Size(oasis_img_size)\n",
        "\n",
        "# image and regularization loss\n",
        "criterion = losses.local_NCC_2d(volshape=img_size, lbd=1) #0.01\n",
        "#criterion = losses.MinVarAndGrad2d(volshape=img_size, lbd=0.1) #0.01\n",
        "\n",
        "# segmentation loss\n",
        "seg_loss = losses.DiceWarpLoss2d(img_size)\n",
        "lambda_seg = 0.5\n",
        "\n",
        "mmnet = models.GroupNet(in_channels=1, out_channels=2, img_size=img_size).to(device)  # updated note: have vxms.models.MultiMorph now.\n",
        "\n",
        "optimizer = optim.Adam(mmnet.parameters(), lr=0.001) #0.01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce2cd61",
      "metadata": {
        "id": "7ce2cd61"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf766288",
      "metadata": {
        "id": "bf766288"
      },
      "outputs": [],
      "source": [
        "nb_epochs = 100\n",
        "batch_size = 1\n",
        "data_loader = dataloader_oasis_train\n",
        "# move the model to the device\n",
        "mmnet = mmnet.to(device)\n",
        "\n",
        "pbar = trange(nb_epochs)\n",
        "loss_hist = np.zeros(nb_epochs)\n",
        "\n",
        "for i in pbar:\n",
        "    total_running_loss = list()\n",
        "    mmnet.train()\n",
        "    for sample in data_loader:\n",
        "        images = sample['image'].to(device)\n",
        "        segmentations = sample['segmentation'].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # predict the warp fields\n",
        "        predw = mmnet(images)\n",
        "        # compute the loss\n",
        "        loss = criterion(images, predw)\n",
        "        loss_seg = seg_loss(segmentations,predw)\n",
        "        loss = loss + lambda_seg * loss_seg\n",
        "        total_running_loss.append(loss.item())\n",
        "        #optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # print stats\n",
        "    m = np.mean(total_running_loss)\n",
        "    pbar.set_description(f'{m:.5f}')\n",
        "    loss_hist[i] = m\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0279d288",
      "metadata": {
        "id": "0279d288"
      },
      "source": [
        "#### Visualize the training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14084105",
      "metadata": {
        "id": "14084105"
      },
      "outputs": [],
      "source": [
        "# lets quickly see the training curve\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(loss_hist)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.title('Training Loss')\n",
        "plt.grid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c97c19",
      "metadata": {
        "id": "10c97c19"
      },
      "source": [
        "# Visualize the warps and atlas on sampels from the train set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72966668",
      "metadata": {
        "id": "72966668"
      },
      "source": [
        "### setup a few plotting and warping functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21ddda9",
      "metadata": {
        "id": "f21ddda9"
      },
      "outputs": [],
      "source": [
        "from utils import warp_seg, warp_image, warp_grid, setup_grid_tensor, plot_row_slices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a907b40d",
      "metadata": {
        "id": "a907b40d"
      },
      "source": [
        "### load a sample and plot the images and segmentations after warping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4f9954",
      "metadata": {
        "id": "cc4f9954"
      },
      "outputs": [],
      "source": [
        "img_size = oasis_img_size\n",
        "dataset = dataset_oasis_train\n",
        "warp_dim = img_size\n",
        "\n",
        "# set up the train data loader\n",
        "mmnet.to(device)\n",
        "gen =  iter(DataLoader(dataset,batch_size=1,shuffle=False))\n",
        "\n",
        "# grab a sample from the data loader\n",
        "sample = next(gen)\n",
        "images = sample['image'].to(device)\n",
        "segs = sample['segmentation'].to(device)\n",
        "N_images = np.shape(images)[1]\n",
        "\n",
        "# warp and plot original, warped images\n",
        "warped, predicted_warp = warp_image(images,mmnet,img_size)\n",
        "warped_seg = warp_seg(segs, predicted_warp, img_size=img_size)\n",
        "\n",
        "# plot the original and warped images\n",
        "plot_row_slices(images, do_colorbars=False, suptitle='Original Images')\n",
        "plot_row_slices(warped, do_colorbars=False, suptitle='Warped Images')\n",
        "\n",
        "# plot the original and warped segmentations\n",
        "plot_row_slices(torch.round(torch.argmax(segs, dim=2, keepdim=True)), do_colorbars=False, cmaps=['turbo']*N_images, suptitle='Original Segmentations')\n",
        "plot_row_slices(torch.round(torch.argmax(warped_seg, dim=2, keepdim=True)), do_colorbars=False, cmaps=['turbo']*N_images, suptitle='Warped Segmentations')\n",
        "\n",
        "# Create a grid and plot the warped grid\n",
        "grids = setup_grid_tensor(N_slices=N_images,spacing=5, img_size=img_size).to(device)\n",
        "warped_grid = warp_grid(grids, predicted_warp, warp_dim=img_size)\n",
        "plot_row_slices(warped_grid, do_colorbars=False, suptitle='Warped Grid')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5afb6cfe",
      "metadata": {
        "id": "5afb6cfe"
      },
      "source": [
        "### visualize the resultant atlases, and compare to constructing an atlas by taking the mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cffdefa",
      "metadata": {
        "id": "0cffdefa"
      },
      "outputs": [],
      "source": [
        "# plot mean shapes\n",
        "atl = torch.mean(images, dim=1, keepdims=True)\n",
        "atlw = torch.mean(warped, dim=1, keepdims=True)\n",
        "slices = [f.cpu().detach().numpy() for f in [atl, atlw]]\n",
        "titles = ['Atlas Computed by Taking the Mean', 'MultiMorph Atlas']\n",
        "ne.plot.slices(slices, do_colorbars=True, titles=titles)\n",
        "\n",
        "# plot mean segmentations\n",
        "mean_seg = torch.round(torch.argmax(torch.mean(segs,dim=1,keepdim=True), dim=2, keepdims=True))\n",
        "mean_warped_seg = torch.round(torch.argmax(torch.mean(warped_seg, dim=1, keepdims=True), dim=2, keepdim=True))\n",
        "slices = [f.cpu().detach().numpy() for f in [mean_seg, mean_warped_seg]]\n",
        "titles = ['Segmentations of Mean Atlas', 'Segmentations of MultiMorph Atlas']\n",
        "ne.plot.slices(slices, do_colorbars=True, titles=titles, cmaps=['turbo']*len(slices))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33187e67",
      "metadata": {
        "id": "33187e67"
      },
      "source": [
        "# Construct an Atlas on the Entire Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5153d75c",
      "metadata": {
        "id": "5153d75c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "mmnet = mmnet.to('cpu')\n",
        "mmnet.eval()\n",
        "warp_layer = layers.group.Warp2d(img_size)\n",
        "for sample in dataloader_oasis_test:\n",
        "    st = time.time()\n",
        "    images = sample['image'].to('cpu')\n",
        "    segmentations = sample['segmentation'].to('cpu')\n",
        "    # predict the warp fields\n",
        "    predw = mmnet(images)\n",
        "\n",
        "    # warp and plot original, warped images\n",
        "    warped = warp_layer(images, predw)\n",
        "    warped_seg = warp_layer(segmentations, predw)\n",
        "    #warped_seg = warp_seg(segmentations, predicted_warp, img_size=img_size)\n",
        "\n",
        "# construct the atlases\n",
        "atlas = torch.mean(warped, dim=1, keepdims=True)\n",
        "atlas_segmentation = torch.round(torch.argmax(torch.mean(warped_seg, dim=1, keepdims=True), dim=2, keepdim=True))\n",
        "\n",
        "et = time.time()\n",
        "print(f'Atlas Construction took {et-st:.3f} seconds for {images.shape[1]} images')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d4dc429",
      "metadata": {
        "id": "8d4dc429"
      },
      "source": [
        "#### plot the constructed atlases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecc9e26",
      "metadata": {
        "id": "fecc9e26"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot these two side by side\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(atlas[0, 0, 0, ...].cpu().detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('MultiMorph Atlas')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(atlas_segmentation[0, 0, 0, ...].cpu().detach().numpy(), cmap='turbo')\n",
        "plt.axis('off')\n",
        "plt.title('Segmentations of MultiMorph Atlas')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50378049",
      "metadata": {
        "id": "50378049"
      },
      "source": [
        "### save the atlases (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf28d39",
      "metadata": {
        "id": "5cf28d39"
      },
      "outputs": [],
      "source": [
        "atlas_path = 'oasis_atlas_2d.nii.gz'\n",
        "atlas_segmentation_path = 'oasis_atlas_segmentation_2d.nii.gz'\n",
        "nib.save(nib.Nifti1Image(atlas[0, 0, 0, ...].cpu().detach().numpy(), np.eye(4)), atlas_path)\n",
        "nib.save(nib.Nifti1Image(atlas_segmentation[0, 0, 0, ...].float().cpu().detach().numpy(), np.eye(4)), atlas_segmentation_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mapping",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}